{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:25.826895Z",
     "start_time": "2019-02-25T00:38:24.349886Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost\n",
    "import time\n",
    "import gc\n",
    "import os\n",
    "import lightgbm as lgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score,\\\n",
    "roc_auc_score, f1_score, confusion_matrix, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:44.938424Z",
     "start_time": "2019-02-25T00:38:28.491013Z"
    }
   },
   "outputs": [],
   "source": [
    "# sessions\n",
    "with open (os.path.expanduser(\"~/USF/adv_ml/final/LeanPlum/session.pkl\"), \"rb\") as f:\n",
    "    sessions = pickle.load(f)\n",
    "\n",
    "# event\n",
    "with open (os.path.expanduser(\"~/USF/adv_ml/final/LeanPlum/events.pkl\"), \"rb\") as f:\n",
    "    events = pickle.load(f)\n",
    "\n",
    "# choose certain columns    \n",
    "event_df = events[[\"user_id_hash\", \"event_timestamp\", \"event\", \"event_value\"]] \n",
    "session_part = sessions[[\"user_id_hash\", \"previous_sessions_duration\", \"start_timestamp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data\n",
    "\n",
    "- Labels for validation set : Dec1 - Dec7, Dec1 - Dec15\n",
    "- Features for validation set :  Oct15 - Nov30\n",
    "\n",
    "- Labels for training set : Nov15 - Dec23, Nov15 - Nov30\n",
    "- Features for training set :  Oct1 - Nov15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:53.140600Z",
     "start_time": "2019-02-25T00:38:44.957436Z"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.DataFrame(list(events.user_id_hash.unique()))\n",
    "users.columns = [\"user_id_hash\"]\n",
    "\n",
    "# first validation label: Dec1 - Dec7\n",
    "\n",
    "dec_event = event_df[(event_df[\"event_timestamp\"] >= 1543651199000) &  #  >= Fri Nov 30 2018 23:59:59 GMT-0800\n",
    "                  (event_df[\"event_timestamp\"] < 1544255999000)] #  < Fri Dec 07 2018 23:59:59 GMT-0800\n",
    "puser1 = set(dec_event[dec_event[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "\n",
    "# for validation, the users include all unique users\n",
    "users_val = users.copy()\n",
    "labels1 = []\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser1:\n",
    "        labels1.append(1)\n",
    "    else:\n",
    "        labels1.append(0)\n",
    "# label and add to val\n",
    "users_val[\"purchased1\"] = pd.DataFrame(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:56.306922Z",
     "start_time": "2019-02-25T00:38:53.142985Z"
    }
   },
   "outputs": [],
   "source": [
    "# second validation label: Dec1-Dec14\n",
    "\n",
    "dec2_event = event_df[(event_df[\"event_timestamp\"] >= 1543651199000)] #  >= Fri Nov 30 2018 23:59:59 GMT-0800\n",
    "puser2 = set(dec2_event[dec2_event[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "\n",
    "labels2 = []\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser2:\n",
    "        labels2.append(1)\n",
    "    else:\n",
    "        labels2.append(0)\n",
    "\n",
    "users_val[\"purchased2\"] = pd.DataFrame(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:39:00.462500Z",
     "start_time": "2019-02-25T00:38:56.320257Z"
    }
   },
   "outputs": [],
   "source": [
    "# first training label : Nov 15, Nov 23\n",
    "nov_event = event_df[(event_df[\"event_timestamp\"] >= 1542268800000) &  # from Mon Nov 15 2018 00:00:00 GMT-0700\n",
    "                     (event_df[\"event_timestamp\"] < 1542960000000)] # Fri Nov 23 2018 00:00:00 GMT-0800\n",
    "\n",
    "puser1 = set(nov_event[nov_event[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "users_train = users.copy()\n",
    "labels1 = []\n",
    "\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser1:\n",
    "        labels1.append(1)\n",
    "    else:\n",
    "        labels1.append(0)\n",
    "\n",
    "users_train[\"purchased1\"] = pd.DataFrame(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:39:05.507867Z",
     "start_time": "2019-02-25T00:39:00.465981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>purchased1</th>\n",
       "      <th>purchased2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999524249720812f2d8c0390293efd58e1ac84d587a01c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc009148ee26d658e0240c7b7f6a258790a457737f96e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  purchased1  purchased2\n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...           0           1\n",
       "1  43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...           0           0\n",
       "2  999524249720812f2d8c0390293efd58e1ac84d587a01c...           0           0\n",
       "3  4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...           0           0\n",
       "4  dc009148ee26d658e0240c7b7f6a258790a457737f96e8...           0           0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second training label: Nov 15, Nov 30\n",
    "nov2_event = event_df[(event_df[\"event_timestamp\"] >= 1542268800000) & # from Mon Nov 15 2018 00:00:00 GMT-0700\n",
    "                      (event_df[\"event_timestamp\"] < 1543478400000)]# till Thu Nov 29 2018 00:00:00 GMT-0800\n",
    "puser2 = set(event_df[event_df[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "labels2 = []\n",
    "\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser2:\n",
    "        labels2.append(1)\n",
    "    else:\n",
    "        labels2.append(0)\n",
    "\n",
    "users_train[\"purchased2\"] = pd.DataFrame(labels2)\n",
    "\n",
    "users_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:40:50.483280Z",
     "start_time": "2019-02-25T00:40:43.210069Z"
    }
   },
   "outputs": [],
   "source": [
    "val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "#val_feature = val_feature[[]].apply(lambda x: x.fillna(0))\n",
    "\n",
    "session_raw_val = sessions[(sessions['start_timestamp']>= 1539586800000) &  # Oct15 - Nov30\n",
    "                   (sessions['start_timestamp']< 1543651199000)]\n",
    "\n",
    "train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "session_raw_train = sessions[(sessions['start_timestamp']< 1542268800000)]\n",
    "#train_feature = train_feature.apply(lambda x: x.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from Event and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:19:20.248007Z",
     "start_time": "2019-02-25T01:18:48.906842Z"
    }
   },
   "outputs": [],
   "source": [
    "###### First version, not used anymore ######\n",
    "\n",
    "#event_list = event_df.event.value_counts()[:50].index\n",
    "# First version, not used anymore\n",
    "def features_event_2(val_raw,val_user,cut_time,session_raw):# cut time is the cut stamp for feature/label \n",
    "    \n",
    "    eventvalue = val_raw[val_raw[\"event\"]==\"8\"][[\"user_id_hash\", \"event_value\"]].\\\n",
    "                groupby(\"user_id_hash\").sum().reset_index()\n",
    "    result = val_user.join(eventvalue.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 2: number of purchase\n",
    "    purchase_times = val_raw[val_raw[\"event\"]==\"8\"].groupby(\"user_id_hash\")\\\n",
    "                    .size().reset_index(name='purchase_counts')\n",
    "    result = result.join(purchase_times.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 3: whether or not purchase\n",
    "    #user_purd = set(val_raw[val_raw['event']=='8'].user_id_hash)\n",
    "    #result['past_buy'] = [1 if uid in user_purd else 0 for uid in result['user_id_hash']]\n",
    "    \n",
    "    # feature 4: total count of different events in event: top 50 events\n",
    "    event_list = ['0','5','1']\n",
    "    \n",
    "    for e in event_list:\n",
    "        event_tmp = val_raw[val_raw[\"event\"]==e].groupby(\"user_id_hash\").size().reset_index(name=f'event{e}_count')\n",
    "        result = result.join(event_tmp.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 5: median, last event time difference to cutoff time\n",
    "    first_last = val_raw.groupby(\"user_id_hash\")['event_timestamp'].agg(['median','last']).reset_index()\n",
    "    first_last['median_diff'] = cut_time - first_last['median']\n",
    "    first_last['last_diff'] = cut_time - first_last['last']\n",
    "    first_last['user_id_hash'] = first_last['user_id_hash'].astype(str)\n",
    "    result = result.join(first_last[['user_id_hash','median_diff','last_diff']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")\n",
    "\n",
    "    '''\n",
    "    session_avg = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('mean').reset_index(name='avg_duration')\n",
    "    session_avg['avg_duration'] = session_avg['avg_duration'].fillna(0)\n",
    "    result = result.join(session_avg[['user_id_hash','avg_duration']].set_index(\"user_id_hash\"),\\\n",
    "                 on=\"user_id_hash\", how=\"left\")  \n",
    "    '''\n",
    "    \n",
    "    session_sum = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('sum').reset_index(name='sum_duration')\n",
    "    session_sum['sum_duration'] = session_sum['sum_duration'].fillna(0)\n",
    "    result = result.join(session_sum[['user_id_hash','sum_duration']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    session_count = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('count').reset_index(name='session_count')\n",
    "    session_count['session_count'] = session_count['session_count'].fillna(0)\n",
    "    result = result.join(session_count[['user_id_hash','session_count']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    #result[['median_diff','last_diff','avg_duration','sum_duration']] = \\\n",
    "    #result[['median_diff','last_diff','avg_duration','sum_duration']].apply(lambda x:x/3.6e+6)\n",
    "    # 8.64e+7 = 1 day in millseconds\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "#train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "train_feature_2 = features_event_2(train_raw,users_train,1542268800000,session_raw_train)\n",
    "\n",
    "#val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "#                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "val_feature_2 = features_event_2(val_raw,users_val,1543651199000, session_raw_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature list for model1(7 days):\n",
    "- event_value\n",
    "- sum_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:12.163752Z",
     "start_time": "2019-02-25T03:22:08.673938Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_model_1(val_raw,val_user,cut_time,session_raw):# cut time is the cut stamp for feature/label \n",
    "    \n",
    "    eventvalue = val_raw[val_raw[\"event\"]==\"8\"][[\"user_id_hash\", \"event_value\"]].\\\n",
    "                groupby(\"user_id_hash\").sum().reset_index()\n",
    "    result = val_user.join(eventvalue.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "        \n",
    "    # feature 3: whether or not purchase\n",
    "    #user_purd = set(val_raw[val_raw['event']=='8'].user_id_hash)\n",
    "    #result['past_buy'] = [1 if uid in user_purd else 0 for uid in result['user_id_hash']]\n",
    "    \n",
    "    # feature 4: total count of different events in event: top 50 events\n",
    "\n",
    "    \n",
    "    session_sum = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('sum').reset_index(name='sum_duration')\n",
    "    session_sum['sum_duration'] = session_sum['sum_duration'].fillna(0)\n",
    "    result = result.join(session_sum[['user_id_hash','sum_duration']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    # SESSIONS\n",
    "    d = {'iPhone OS' : 'iOS', 'iOS' : 'iOS','Android OS': 'Android OS' }\n",
    "    session_raw['os_name'] = session_raw['os_name'].map(d)\n",
    "    \n",
    "    #Feature #1: number of sessions per user\n",
    "    num_sessions =session_raw.groupby(['user_id_hash'])['session_id'].count().reset_index()\n",
    "    result = result.join(num_sessions.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # Feature #2: is_first session\n",
    "    user_first_session = session_raw.groupby(['user_id_hash'])['is_user_first_session'].mean().reset_index()\n",
    "    user_first_session['first_time'] = 0\n",
    "    user_first_session.loc[user_first_session['is_user_first_session']==1,'first_time']=1\n",
    "    result = result.join(user_first_session.drop(['is_user_first_session'], axis = 1).set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    # Feature #3 Country of origin\n",
    "    sessions_user =session_raw.drop([ 'session_id', 'start_timestamp','previous_sessions_duration',\\\n",
    "                                 'user_created_timestamp',  'session_index',\\\n",
    "                                  'latitude', 'longitude', 'is_user_first_session',\n",
    "                                 'locale', 'city'], axis =1)\n",
    "    user_country = sessions_user.drop(['os_name', 'device_id', 'region', 'timezone', 'timezone_offset'], axis= 1)\n",
    "    user_country.drop_duplicates(inplace = True)\n",
    "    country_one_hot = pd.get_dummies(user_country['country'])\n",
    "    user_country = pd.concat([user_country.drop(['country'], axis = 1), country_one_hot], axis = 1).reset_index()\n",
    "    \n",
    "    result = result.join(user_country.drop(['index'], axis = 1).set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # Feature #4 OS System\n",
    "    d = {'iPhone OS' : 'iOS', 'iOS' : 'iOS','Android OS': 'Android OS' }\n",
    "    session_raw['os_name'] = session_raw['os_name'].map(d)\n",
    "    \n",
    "    user_os = sessions_user.drop(['country', 'device_id', 'region', 'timezone', 'timezone_offset'], axis= 1)\n",
    "    user_os.drop_duplicates(inplace = True)\n",
    "    os_one_hot = pd.get_dummies(user_os['os_name'])\n",
    "    user_os = pd.concat([user_os.drop(['os_name'], axis = 1),os_one_hot], axis =1).reset_index()\n",
    "    result = result.join(user_os.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "#train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "train_feature_m1 = features_model_1(train_raw,users_train,1542268800000,session_raw_train)\n",
    "\n",
    "#val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "#                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "val_feature_m1 = features_model_1(val_raw,users_val,1543651199000, session_raw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:44:54.398479Z",
     "start_time": "2019-02-25T01:44:54.388873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>purchased1</th>\n",
       "      <th>purchased2</th>\n",
       "      <th>event_value</th>\n",
       "      <th>sum_duration</th>\n",
       "      <th>session_id</th>\n",
       "      <th>first_time</th>\n",
       "      <th>AE</th>\n",
       "      <th>AG</th>\n",
       "      <th>AL</th>\n",
       "      <th>...</th>\n",
       "      <th>NU</th>\n",
       "      <th>PM</th>\n",
       "      <th>ST</th>\n",
       "      <th>MS</th>\n",
       "      <th>NF</th>\n",
       "      <th>FK</th>\n",
       "      <th>CU</th>\n",
       "      <th>index</th>\n",
       "      <th>Android OS</th>\n",
       "      <th>iOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.492188</td>\n",
       "      <td>857156805.0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6074816.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999524249720812f2d8c0390293efd58e1ac84d587a01c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc009148ee26d658e0240c7b7f6a258790a457737f96e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  purchased1  purchased2  \\\n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...           0           1   \n",
       "1  43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...           0           0   \n",
       "2  999524249720812f2d8c0390293efd58e1ac84d587a01c...           0           0   \n",
       "3  4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...           0           0   \n",
       "4  dc009148ee26d658e0240c7b7f6a258790a457737f96e8...           0           0   \n",
       "\n",
       "   event_value  sum_duration  session_id  first_time   AE   AG   AL ...    NU  \\\n",
       "0     3.492188   857156805.0          31           0  0.0  0.0  0.0 ...   0.0   \n",
       "1     0.000000     6074816.0           3           0  0.0  0.0  0.0 ...   0.0   \n",
       "2     0.000000           0.0           1           1  0.0  0.0  0.0 ...   0.0   \n",
       "3     0.000000           0.0           0           0  NaN  NaN  NaN ...   NaN   \n",
       "4     0.000000           0.0           1           1  0.0  0.0  0.0 ...   0.0   \n",
       "\n",
       "    PM   ST   MS   NF   FK   CU  index  Android OS  iOS  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0    0.0         1.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0   47.0         0.0  1.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0   50.0         0.0  1.0  \n",
       "3  NaN  NaN  NaN  NaN  NaN  NaN    NaN         NaN  NaN  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0   52.0         1.0  0.0  \n",
       "\n",
       "[5 rows x 238 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_m1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature list for model1(15 days):\n",
    "- median_diff\n",
    "- purchase_counts\n",
    "- last_diff\n",
    "- session_count\n",
    "- sum_duration\n",
    "- event 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:21:56.849977Z",
     "start_time": "2019-02-25T03:21:41.470372Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_model_2(val_raw,val_user,cut_time,session_raw):# cut time is the cut stamp for feature/label \n",
    "    \n",
    "    # feature 2: number of purchase\n",
    "    purchase_times = val_raw[val_raw[\"event\"]==\"8\"].groupby(\"user_id_hash\")\\\n",
    "                    .size().reset_index(name='purchase_counts')\n",
    "    result = val_user.join(purchase_times.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 3: whether or not purchase\n",
    "    #user_purd = set(val_raw[val_raw['event']=='8'].user_id_hash)\n",
    "    #result['past_buy'] = [1 if uid in user_purd else 0 for uid in result['user_id_hash']]\n",
    "    \n",
    "    # feature 4: total count of different events in event: top 50 events\n",
    "\n",
    "    # feature 5: median, last event time difference to cutoff time\n",
    "    first_last = val_raw.groupby(\"user_id_hash\")['event_timestamp'].agg(['median','last']).reset_index()\n",
    "    first_last['median_diff'] = cut_time - first_last['median']\n",
    "    first_last['last_diff'] = cut_time - first_last['last']\n",
    "    first_last['user_id_hash'] = first_last['user_id_hash'].astype(str)\n",
    "    result = result.join(first_last[['user_id_hash','median_diff','last_diff']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    session_sum = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('sum').reset_index(name='sum_duration')\n",
    "    session_sum['sum_duration'] = session_sum['sum_duration'].fillna(0)\n",
    "    result = result.join(session_sum[['user_id_hash','sum_duration']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    session_count = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('count').reset_index(name='session_count')\n",
    "    session_count['session_count'] = session_count['session_count'].fillna(0)\n",
    "    result = result.join(session_count[['user_id_hash','session_count']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    event_list = ['5']\n",
    "    \n",
    "    for e in event_list:\n",
    "        event_tmp = val_raw[val_raw[\"event\"]==e].groupby(\"user_id_hash\").size().reset_index(name=f'event{e}_count')\n",
    "        result = result.join(event_tmp.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # SESSIONS\n",
    "    d = {'iPhone OS' : 'iOS', 'iOS' : 'iOS','Android OS': 'Android OS' }\n",
    "    session_raw['os_name'] = session_raw['os_name'].map(d)\n",
    "    \n",
    "    #Feature #1: number of sessions per user\n",
    "    num_sessions =session_raw.groupby(['user_id_hash'])['session_id'].count().reset_index()\n",
    "    result = result.join(num_sessions.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # Feature #2: is_first session\n",
    "    user_first_session = session_raw.groupby(['user_id_hash'])['is_user_first_session'].mean().reset_index()\n",
    "    user_first_session['first_time'] = 0\n",
    "    user_first_session.loc[user_first_session['is_user_first_session']==1,'first_time']=1\n",
    "    result = result.join(user_first_session.drop(['is_user_first_session'], axis = 1).set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    # Feature #3 Country of origin\n",
    "    sessions_user =session_raw.drop([ 'session_id', 'start_timestamp','previous_sessions_duration',\\\n",
    "                                 'user_created_timestamp',  'session_index',\\\n",
    "                                  'latitude', 'longitude', 'is_user_first_session',\n",
    "                                 'locale', 'city'], axis =1)\n",
    "    user_country = sessions_user.drop(['os_name', 'device_id', 'region', 'timezone', 'timezone_offset'], axis= 1)\n",
    "    user_country.drop_duplicates(inplace = True)\n",
    "    country_one_hot = pd.get_dummies(user_country['country'])\n",
    "    user_country = pd.concat([user_country.drop(['country'], axis = 1), country_one_hot], axis = 1).reset_index()\n",
    "    \n",
    "    result = result.join(user_country.drop(['index'], axis = 1).set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # Feature #4 OS System\n",
    "    d = {'iPhone OS' : 'iOS', 'iOS' : 'iOS','Android OS': 'Android OS' }\n",
    "    session_raw['os_name'] = session_raw['os_name'].map(d)\n",
    "    \n",
    "    user_os = sessions_user.drop(['country', 'device_id', 'region', 'timezone', 'timezone_offset'], axis= 1)\n",
    "    user_os.drop_duplicates(inplace = True)\n",
    "    os_one_hot = pd.get_dummies(user_os['os_name'])\n",
    "    user_os = pd.concat([user_os.drop(['os_name'], axis = 1),os_one_hot], axis =1).reset_index()\n",
    "    result = result.join(user_os.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "#train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "train_feature_m2 = features_model_2(train_raw,users_train,1542268800000,session_raw_train)\n",
    "\n",
    "#val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "#                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "val_feature_m2 = features_model_2(val_raw,users_val,1543651199000, session_raw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:21:56.872101Z",
     "start_time": "2019-02-25T03:21:56.855458Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>purchased1</th>\n",
       "      <th>purchased2</th>\n",
       "      <th>purchase_counts</th>\n",
       "      <th>median_diff</th>\n",
       "      <th>last_diff</th>\n",
       "      <th>sum_duration</th>\n",
       "      <th>session_count</th>\n",
       "      <th>event5_count</th>\n",
       "      <th>session_id</th>\n",
       "      <th>...</th>\n",
       "      <th>NU</th>\n",
       "      <th>PM</th>\n",
       "      <th>ST</th>\n",
       "      <th>MS</th>\n",
       "      <th>NF</th>\n",
       "      <th>FK</th>\n",
       "      <th>CU</th>\n",
       "      <th>index</th>\n",
       "      <th>Android OS</th>\n",
       "      <th>iOS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.162291e+09</td>\n",
       "      <td>3.265969e+08</td>\n",
       "      <td>857156805.0</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.815455e+08</td>\n",
       "      <td>3.398837e+08</td>\n",
       "      <td>6074816.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999524249720812f2d8c0390293efd58e1ac84d587a01c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.438209e+09</td>\n",
       "      <td>2.437954e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc009148ee26d658e0240c7b7f6a258790a457737f96e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.045302e+09</td>\n",
       "      <td>1.902918e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  purchased1  purchased2  \\\n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...           0           1   \n",
       "1  43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...           0           0   \n",
       "2  999524249720812f2d8c0390293efd58e1ac84d587a01c...           0           0   \n",
       "3  4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...           0           0   \n",
       "4  dc009148ee26d658e0240c7b7f6a258790a457737f96e8...           0           0   \n",
       "\n",
       "   purchase_counts   median_diff     last_diff  sum_duration  session_count  \\\n",
       "0                1  2.162291e+09  3.265969e+08   857156805.0             35   \n",
       "1                0  3.815455e+08  3.398837e+08     6074816.0              3   \n",
       "2                0  2.438209e+09  2.437954e+09           0.0              1   \n",
       "3                0           NaN           NaN           0.0              1   \n",
       "4                0  2.045302e+09  1.902918e+09           0.0              1   \n",
       "\n",
       "   event5_count  session_id ...    NU   PM   ST   MS   NF   FK   CU  index  \\\n",
       "0            22          31 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0    0.0   \n",
       "1             3           3 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   47.0   \n",
       "2             1           1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   50.0   \n",
       "3             0           0 ...   NaN  NaN  NaN  NaN  NaN  NaN  NaN    NaN   \n",
       "4             1           1 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0   52.0   \n",
       "\n",
       "   Android OS  iOS  \n",
       "0         1.0  0.0  \n",
       "1         0.0  1.0  \n",
       "2         0.0  1.0  \n",
       "3         NaN  NaN  \n",
       "4         1.0  0.0  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_m2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X,y split for MODEL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:12.382066Z",
     "start_time": "2019-02-25T03:22:12.358407Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_m1 = train_feature_m1[train_feature_m1.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "y_train_1 = train_feature_m1[[\"purchased1\"]]\n",
    "X_val_m1 = val_feature_m1[val_feature_m1.columns.difference([\"purchased1\",\"purchased2\",'user_id_hash'])]\n",
    "y_val_1 = val_feature_m1[['purchased1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X,y split for MODEL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:21:56.959847Z",
     "start_time": "2019-02-25T03:21:56.876365Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_m2 = train_feature_m2[train_feature_m2.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "y_train_2 = train_feature_m2[[\"purchased2\"]]\n",
    "X_val_m2 = val_feature_m2[val_feature_m2.columns.difference([\"purchased1\",\"purchased2\",'user_id_hash'])]\n",
    "y_val_2 = val_feature_m2[['purchased2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search on Light GBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:19:40.095219Z",
     "start_time": "2019-02-25T03:05:13.882967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search start...\n",
      "* training model1_7day \n",
      "--> Best AUC:0.9193449297839996 using {'n_estimators': 350, 'bagging_fraction': 0.8, 'learning_rate': 0.05, 'is_unbalance': True, 'max_bin': 3, 'boosting_type': 'gbdt', 'max_depth': 5, 'feature_fraction': 0.7, 'lambda_l1': 20, 'objective': 'binary', 'metric': 'auc'}\n",
      "* training model2_14day \n",
      "--> Best AUC:0.9366721545516677 using {'n_estimators': 300, 'bagging_fraction': 0.9, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 20, 'boosting_type': 'dart', 'max_depth': 2, 'feature_fraction': 0.7, 'lambda_l1': 40, 'objective': 'binary', 'metric': 'auc'}\n"
     ]
    }
   ],
   "source": [
    "## Random Search\n",
    "# loop for random search\n",
    "n_iterations=20\n",
    "\n",
    "print (\"Random search start...\")\n",
    "\n",
    "for col in ['model1_7day','model2_14day']:\n",
    "    print(f\"* training {col} \")\n",
    "    #y = target[col]\n",
    "    roc_auc_mean = []\n",
    "    dict_list = []\n",
    "    \n",
    "    for i in range(0, n_iterations):\n",
    "\n",
    "        param_dist = {'n_estimators' : choice([250,300,350,400,450]),\n",
    "                  'bagging_fraction': choice([0.5, 0.7, 0.8, 0.9]),\n",
    "                  'learning_rate': choice([0.05, 0.1, 0.3, 0.5]),\n",
    "                  'is_unbalance': True,\n",
    "                  'max_bin': choice([3, 5, 10, 15, 18, 20, 25]),\n",
    "                  'boosting_type' : choice(['gbdt', 'dart']),\n",
    "                  'max_depth': choice([2,3,4,5]),      \n",
    "                  'feature_fraction': choice([0.7, 0.8, 0.9]),\n",
    "                  'lambda_l1': choice([0, 10, 20, 30, 40]),\n",
    "                  'objective': 'binary', \n",
    "                  'metric': 'auc'} \n",
    "\n",
    "        roc_l = []\n",
    "        \n",
    "       # y_train_1,y_train_2,X_train\n",
    "       # y_val_1,y_val_2,X_val\n",
    "\n",
    "        # training\n",
    "        if col == 'model1_7day':\n",
    "            X_train = X_train_m1\n",
    "            X_val = X_val_m1\n",
    "            y_train = y_train_1\n",
    "            y_val = y_val_1\n",
    "        else: \n",
    "            X_train = X_train_m2\n",
    "            X_val = X_val_m2\n",
    "            y_train = y_train_2\n",
    "            y_val = y_val_2\n",
    "            \n",
    "        gbm = lgb.LGBMClassifier(**param_dist)\n",
    "        gbm.fit(X_train,y_train)\n",
    "        # predicting\n",
    "        y_pred = np.round(gbm.predict_proba(X_val)[:,1],3)\n",
    "        \n",
    "        roc = roc_auc_score(y_val, y_pred)\n",
    "        roc_l.append(roc)\n",
    "\n",
    "        roc_array = np.asarray(roc_l)\n",
    "\n",
    "        roc_auc_mean.append(roc_array.mean())\n",
    "        dict_list.append(param_dist)\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "    results_pd = pd.DataFrame({\"roc_auc_mean\": roc_auc_mean,\"parameters\": dict_list})    \n",
    "    results_pd.sort_values(\"roc_auc_mean\", ascending = False, axis = 0, inplace = True)\n",
    "    \n",
    "    top_pd = results_pd.head(1)\n",
    "    \n",
    "    print(f\"--> Best AUC:{top_pd.iloc[0,0]} using {top_pd.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:53.362510Z",
     "start_time": "2019-02-25T03:22:26.272988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score = 0.9197620403754481\n",
      "Time use:25.014s\n"
     ]
    }
   ],
   "source": [
    "# using the results from random search\n",
    "para_list_7days = {'n_estimators': 350, 'bagging_fraction': 0.8, 'learning_rate': 0.05, \\\n",
    "                   'is_unbalance': True, 'max_bin': 3, 'boosting_type': 'gbdt', 'max_depth': 5, \\\n",
    "                   'feature_fraction': 0.7, 'lambda_l1': 20, 'objective': 'binary', 'metric': 'auc'}\n",
    "t = time.time()\n",
    "# Model for 7 days\n",
    "param = para_list_7days\n",
    "gbm = lgb.LGBMClassifier(**param)\n",
    "gbm.fit(X_train_m1, y_train_1)\n",
    "# predicting\n",
    "probabilities = gbm.predict_proba(X_val_m1)\n",
    "#preds = gbm.predict(X_val_m1)\n",
    "score = probabilities[:, 1]\n",
    "\n",
    "print(f'auc score = {roc_auc_score(y_val_1,score)}')\n",
    "print(f\"Time use:{time.time()-t:.3f}s\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:53.387964Z",
     "start_time": "2019-02-25T03:22:53.371536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>64</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>67</td>\n",
       "      <td>DE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>73</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>74</td>\n",
       "      <td>FR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>84</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>91</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>111</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>113</td>\n",
       "      <td>first_time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>127</td>\n",
       "      <td>NZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>176</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>177</td>\n",
       "      <td>iOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>282</td>\n",
       "      <td>Android OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>333</td>\n",
       "      <td>last_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>494</td>\n",
       "      <td>event5_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>835</td>\n",
       "      <td>median_diff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Value       Feature\n",
       "220     64            AD\n",
       "221     67            DE\n",
       "222     73            IN\n",
       "223     74            FR\n",
       "224     84            AU\n",
       "225     91            CA\n",
       "226    111            GB\n",
       "227    113    first_time\n",
       "228    127            NZ\n",
       "229    176            US\n",
       "230    177           iOS\n",
       "231    282    Android OS\n",
       "232    333     last_diff\n",
       "233    494  event5_count\n",
       "234    835   median_diff"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sorted(zip(gbm.feature_importances_,X_train.columns)), columns=['Value','Feature']).tail(15)\n",
    "#sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:59.832891Z",
     "start_time": "2019-02-25T03:22:53.392394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score = 0.9375570228990708\n",
      "Time use:29.510s\n"
     ]
    }
   ],
   "source": [
    "# using the results from random search\n",
    "para_list_14days = {'n_estimators': 300, 'bagging_fraction': 0.9, 'learning_rate': 0.1, \\\n",
    "                    'is_unbalance': True, 'max_bin': 20, 'boosting_type': 'dart', 'max_depth': 2,\\\n",
    "                    'feature_fraction': 0.7, 'lambda_l1': 40, 'objective': 'binary', 'metric': 'auc'}\n",
    "\n",
    "t = time.time()\n",
    "# Model for 7 days\n",
    "param = para_list_14days\n",
    "gbm2 = lgb.LGBMClassifier(**param)\n",
    "gbm2.fit(X_train_m2, y_train_2)\n",
    "# predicting\n",
    "probabilities = gbm2.predict_proba(X_val_m2)\n",
    "#preds = gbm2.predict(X_val)\n",
    "score = probabilities[:, 1]\n",
    "print(f'auc score = {roc_auc_score(y_val_2,score)}')\n",
    "print(f\"Time use:{time.time()-t:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:59.859326Z",
     "start_time": "2019-02-25T03:22:59.844095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>4</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>6</td>\n",
       "      <td>Android OS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>7</td>\n",
       "      <td>GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>8</td>\n",
       "      <td>AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>10</td>\n",
       "      <td>AU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>10</td>\n",
       "      <td>CH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>14</td>\n",
       "      <td>iOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>28</td>\n",
       "      <td>session_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>37</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>48</td>\n",
       "      <td>event5_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>48</td>\n",
       "      <td>last_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>60</td>\n",
       "      <td>median_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>65</td>\n",
       "      <td>session_id</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>188</td>\n",
       "      <td>sum_duration</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>214</td>\n",
       "      <td>purchase_counts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Value          Feature\n",
       "224      4               IN\n",
       "225      6       Android OS\n",
       "226      7               GB\n",
       "227      8               AT\n",
       "228     10               AU\n",
       "229     10               CH\n",
       "230     14              iOS\n",
       "231     28    session_count\n",
       "232     37               US\n",
       "233     48     event5_count\n",
       "234     48        last_diff\n",
       "235     60      median_diff\n",
       "236     65       session_id\n",
       "237    188     sum_duration\n",
       "238    214  purchase_counts"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance for model 2\n",
    "pd.DataFrame(sorted(zip(gbm2.feature_importances_,X_train.columns)), columns=['Value','Feature']).tail(15)\n",
    "#sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test set\n",
    "\n",
    "- test features: Nov1 - Dec15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:10.848141Z",
     "start_time": "2019-02-25T03:23:10.340747Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(os.path.expanduser(\"~/USF/adv_ml/final/sample_submission_2.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:30.060389Z",
     "start_time": "2019-02-25T03:23:15.955685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD</th>\n",
       "      <th>AE</th>\n",
       "      <th>AF</th>\n",
       "      <th>AG</th>\n",
       "      <th>AI</th>\n",
       "      <th>AL</th>\n",
       "      <th>AM</th>\n",
       "      <th>AO</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>...</th>\n",
       "      <th>ZA</th>\n",
       "      <th>ZM</th>\n",
       "      <th>ZW</th>\n",
       "      <th>ZZ</th>\n",
       "      <th>event_value</th>\n",
       "      <th>first_time</th>\n",
       "      <th>iOS</th>\n",
       "      <th>index</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sum_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.492188</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "      <td>857156805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6074816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 235 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AD   AE   AF   AG   AI   AL   AM   AO   AR   AS      ...        ZA   ZM  \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...       0.0  0.0   \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...       0.0  0.0   \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN      ...       NaN  NaN   \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...       0.0  0.0   \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN      ...       NaN  NaN   \n",
       "\n",
       "    ZW   ZZ  event_value  first_time  iOS  index  session_id  sum_duration  \n",
       "0  0.0  0.0     3.492188           0  0.0    0.0          33   857156805.0  \n",
       "1  0.0  0.0     0.000000           0  1.0   47.0           3     6074816.0  \n",
       "2  NaN  NaN     0.000000           0  NaN    NaN           0           0.0  \n",
       "3  0.0  0.0     0.000000           1  0.0   51.0           1           0.0  \n",
       "4  NaN  NaN     0.000000           0  NaN    NaN           0           0.0  \n",
       "\n",
       "[5 rows x 235 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#users = pd.DataFrame(list(events.user_id_hash.unique()))\n",
    "#users.columns = [\"user_id_hash\"]\n",
    "session_raw_test = sessions[(session_part['start_timestamp'] >= 1541055600000)] # Nov 1\n",
    "test_raw = event_df[(event_df[\"event_timestamp\"] >= 1541055600000)] # November 1\n",
    "user_test = users\n",
    "test_feature_m1 = features_model_1(test_raw,user_test,1544860800000,session_raw_test) # Dec 15\n",
    "X_test_m1 = test_feature_m1[test_feature_m1.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "X_test_m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624954, 238)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_m1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624984, 241)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:50.042370Z",
     "start_time": "2019-02-25T03:23:30.062595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AD</th>\n",
       "      <th>AE</th>\n",
       "      <th>AF</th>\n",
       "      <th>AG</th>\n",
       "      <th>AI</th>\n",
       "      <th>AL</th>\n",
       "      <th>AM</th>\n",
       "      <th>AO</th>\n",
       "      <th>AR</th>\n",
       "      <th>AS</th>\n",
       "      <th>...</th>\n",
       "      <th>event5_count</th>\n",
       "      <th>first_time</th>\n",
       "      <th>iOS</th>\n",
       "      <th>index</th>\n",
       "      <th>last_diff</th>\n",
       "      <th>median_diff</th>\n",
       "      <th>purchase_counts</th>\n",
       "      <th>session_count</th>\n",
       "      <th>session_id</th>\n",
       "      <th>sum_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.918597e+09</td>\n",
       "      <td>2.670147e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>33</td>\n",
       "      <td>857156805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>2.931884e+09</td>\n",
       "      <td>2.973545e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6074816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>2.337255e+09</td>\n",
       "      <td>2.337667e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 239 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AD   AE   AF   AG   AI   AL   AM   AO   AR   AS      ...       \\\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...        \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...        \n",
       "2  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN      ...        \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0      ...        \n",
       "4  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN      ...        \n",
       "\n",
       "   event5_count  first_time  iOS  index     last_diff   median_diff  \\\n",
       "0            17           0  0.0    0.0  2.918597e+09  2.670147e+09   \n",
       "1             3           0  1.0   47.0  2.931884e+09  2.973545e+09   \n",
       "2             0           0  NaN    NaN           NaN           NaN   \n",
       "3             1           1  0.0   51.0  2.337255e+09  2.337667e+09   \n",
       "4             0           0  NaN    NaN           NaN           NaN   \n",
       "\n",
       "   purchase_counts  session_count  session_id  sum_duration  \n",
       "0                1             35          33   857156805.0  \n",
       "1                0              3           3     6074816.0  \n",
       "2                0              1           0           0.0  \n",
       "3                0              1           1           0.0  \n",
       "4                0              1           0           0.0  \n",
       "\n",
       "[5 rows x 239 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_m2 = features_model_2(test_raw,user_test,1544860800000,session_raw_test) # Dec 15\n",
    "X_test_m2 = test_feature_m2[test_feature_m2.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "X_test_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:56.373861Z",
     "start_time": "2019-02-25T03:23:53.209661Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_1 = gbm.predict_proba(X_test_m1)\n",
    "pred_2 = gbm2.predict_proba(X_test_m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:56.373861Z",
     "start_time": "2019-02-25T03:23:53.209661Z"
    }
   },
   "outputs": [],
   "source": [
    "test_feature = test_feature_m1.copy()\n",
    "test_feature[\"user_purchase_binary_7_days\"] = pd.DataFrame(pred_1[:,-1])\n",
    "test_feature[\"user_purchase_binary_14_days\"] = pd.DataFrame(pred_2[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:59.538026Z",
     "start_time": "2019-02-25T03:23:58.937612Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = sample[['user_id_hash']].merge(test_feature[['user_id_hash','user_purchase_binary_7_days',\\\n",
    "                                             'user_purchase_binary_14_days']],on='user_id_hash',\\\n",
    "                               how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:59.538026Z",
     "start_time": "2019-02-25T03:23:58.937612Z"
    }
   },
   "outputs": [],
   "source": [
    "# for users do not have previous data, mark as 0\n",
    "submission = submission.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:24:10.974421Z",
     "start_time": "2019-02-25T03:24:10.964996Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:16:04.233592Z",
     "start_time": "2019-02-25T01:16:04.224780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312568, 3)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:24:24.857096Z",
     "start_time": "2019-02-25T03:24:23.329503Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(os.path.expanduser(\"~/USF/adv_ml/final/submission_2\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312568, 3)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def score_1(params):\n",
    "    from sklearn.metrics import log_loss\n",
    "    print(\"Training with params:\")\n",
    "    print(params)\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "    dtrain = xgb.DMatrix(X_train_m1, label=y_train_1)\n",
    "    dvalid = xgb.DMatrix(X_val_m1, label=y_val_1)\n",
    "    model = xgb.train(params, dtrain, params['num_round'])\n",
    "    predictions = model.predict(dvalid).reshape((X_val_m1test.shape[0], 7))\n",
    "    score = log_loss(y_val_1, predictions)\n",
    "    print(\"\\tScore {0}\\n\\n\".format(score))\n",
    "    return {'loss': score, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(trials):\n",
    "    space = {\n",
    "             'num_round': 100,\n",
    "             'learning_rate': hp.quniform('eta', 0.005, 0.05, 0.005),\n",
    "             'max_depth': hp.quniform('max_depth', 3, 14, 1),\n",
    "             'min_child_weight': hp.quniform('min_child_weight', 1, 10, 1),\n",
    "             'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "             'gamma': hp.quniform('gamma', 0.5, 1, 0.01),\n",
    "             'colsample_bytree': hp.quniform('colsample_bytree', 0.4, 1, 0.05),\n",
    "             'num_class' : 7,\n",
    "             'eval_metric': 'merror',\n",
    "             'objective': 'multi:softprob',\n",
    "             'nthread' : 4,\n",
    "             'silent' : 1\n",
    "             }\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=10)\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s, best loss: ?]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.ndarray' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-45e1389ad2c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbest_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-105-b1e689c47377>\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(trials)\u001b[0m\n\u001b[1;32m     15\u001b[0m              }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mbest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.ndarray' object is not callable"
     ]
    }
   ],
   "source": [
    "\n",
    "trials = Trials()\n",
    "best_params = optimize(trials)\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "trials = Trials()\n",
    "best_params = optimize(trials)\n",
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
