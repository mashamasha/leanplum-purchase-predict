{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:25.826895Z",
     "start_time": "2019-02-25T00:38:24.349886Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/ml/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import xgboost\n",
    "import time\n",
    "import gc\n",
    "import lightgbm as lgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "#warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score,\\\n",
    "roc_auc_score, f1_score, confusion_matrix, precision_recall_curve\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from collections import Counter, defaultdict\n",
    "from random import choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:44.938424Z",
     "start_time": "2019-02-25T00:38:28.491013Z"
    }
   },
   "outputs": [],
   "source": [
    "# sessions\n",
    "with open (\"/Users/nanlin/msds/Adv_ML/leanplum/data/LeanPlum/session.pkl\", \"rb\") as f:\n",
    "    sessions = pickle.load(f)\n",
    "\n",
    "# event\n",
    "with open (\"/Users/nanlin/msds/Adv_ML/leanplum/data/LeanPlum/events.pkl\", \"rb\") as f:\n",
    "    events = pickle.load(f)\n",
    "\n",
    "# choose certain columns    \n",
    "event_df = events[[\"user_id_hash\", \"event_timestamp\", \"event\", \"event_value\"]] \n",
    "session_part = sessions[[\"user_id_hash\", \"previous_sessions_duration\", \"start_timestamp\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data\n",
    "\n",
    "- Labels for validation set : Dec1 - Dec7, Dec1 - Dec15\n",
    "- Features for validation set :  Oct15 - Nov30\n",
    "\n",
    "- Labels for training set : Nov15 - Dec23, Nov15 - Nov30\n",
    "- Features for training set :  Oct1 - Nov15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:53.140600Z",
     "start_time": "2019-02-25T00:38:44.957436Z"
    }
   },
   "outputs": [],
   "source": [
    "users = pd.DataFrame(list(events.user_id_hash.unique()))\n",
    "users.columns = [\"user_id_hash\"]\n",
    "\n",
    "# first validation label: Dec1 - Dec7\n",
    "\n",
    "dec_event = event_df[(event_df[\"event_timestamp\"] >= 1543651199000) & \n",
    "                  (event_df[\"event_timestamp\"] < 1544255999000)]\n",
    "puser1 = set(dec_event[dec_event[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "\n",
    "# for validation, the users include all unique users\n",
    "users_val = users\n",
    "labels1 = []\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser1:\n",
    "        labels1.append(1)\n",
    "    else:\n",
    "        labels1.append(0)\n",
    "# label and add to val\n",
    "users_val[\"purchased1\"] = pd.DataFrame(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:38:56.306922Z",
     "start_time": "2019-02-25T00:38:53.142985Z"
    }
   },
   "outputs": [],
   "source": [
    "# second validation label: Dec1-Dec14\n",
    "\n",
    "dec2_event = event_df[(event_df[\"event_timestamp\"] >= 1543651199000)]\n",
    "puser2 = set(dec2_event[dec2_event[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "\n",
    "labels2 = []\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser2:\n",
    "        labels2.append(1)\n",
    "    else:\n",
    "        labels2.append(0)\n",
    "\n",
    "users_val[\"purchased2\"] = pd.DataFrame(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:39:00.462500Z",
     "start_time": "2019-02-25T00:38:56.320257Z"
    }
   },
   "outputs": [],
   "source": [
    "# first training label : Nov 15, Nov 23\n",
    "nov_event = event_df[(event_df[\"event_timestamp\"] >= 1542268800000) & (event_df[\"event_timestamp\"] < 1542960000000)]\n",
    "\n",
    "puser1 = set(nov_event[nov_event[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "users_train = users\n",
    "labels1 = []\n",
    "\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser1:\n",
    "        labels1.append(1)\n",
    "    else:\n",
    "        labels1.append(0)\n",
    "\n",
    "users_train[\"purchased1\"] = pd.DataFrame(labels1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:39:05.507867Z",
     "start_time": "2019-02-25T00:39:00.465981Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>purchased1</th>\n",
       "      <th>purchased2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999524249720812f2d8c0390293efd58e1ac84d587a01c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc009148ee26d658e0240c7b7f6a258790a457737f96e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  purchased1  purchased2\n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...           0           1\n",
       "1  43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...           0           0\n",
       "2  999524249720812f2d8c0390293efd58e1ac84d587a01c...           0           0\n",
       "3  4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...           0           0\n",
       "4  dc009148ee26d658e0240c7b7f6a258790a457737f96e8...           0           0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# second training label: Nov 15, Nov 30\n",
    "nov2_event = event_df[(event_df[\"event_timestamp\"] >= 1542268800000) & (event_df[\"event_timestamp\"] < 1543478400000)]\n",
    "puser2 = set(event_df[event_df[\"event\"] == \"8\"].user_id_hash.unique())\n",
    "labels2 = []\n",
    "\n",
    "for user in list(events.user_id_hash.unique()):\n",
    "    if user in puser2:\n",
    "        labels2.append(1)\n",
    "    else:\n",
    "        labels2.append(0)\n",
    "\n",
    "users_train[\"purchased2\"] = pd.DataFrame(labels2)\n",
    "\n",
    "users_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T00:40:50.483280Z",
     "start_time": "2019-02-25T00:40:43.210069Z"
    }
   },
   "outputs": [],
   "source": [
    "val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "#val_feature = val_feature[[]].apply(lambda x: x.fillna(0))\n",
    "\n",
    "session_raw_val = session_part[(session_part['start_timestamp']>= 1539586800000) &  # Oct15 - Nov30\n",
    "                   (session_part['start_timestamp']< 1543651199000)]\n",
    "\n",
    "train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "session_raw_train = session_part[(session_part['start_timestamp']< 1542268800000)]\n",
    "#train_feature = train_feature.apply(lambda x: x.fillna(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features from Event and Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:19:20.248007Z",
     "start_time": "2019-02-25T01:18:48.906842Z"
    }
   },
   "outputs": [],
   "source": [
    "###### First version, not used anymore ######\n",
    "\n",
    "#event_list = event_df.event.value_counts()[:50].index\n",
    "# First version, not used anymore\n",
    "def features_event_2(val_raw,val_user,cut_time,session_raw):# cut time is the cut stamp for feature/label \n",
    "    \n",
    "    eventvalue = val_raw[val_raw[\"event\"]==\"8\"][[\"user_id_hash\", \"event_value\"]].\\\n",
    "                groupby(\"user_id_hash\").sum().reset_index()\n",
    "    result = val_user.join(eventvalue.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 2: number of purchase\n",
    "    purchase_times = val_raw[val_raw[\"event\"]==\"8\"].groupby(\"user_id_hash\")\\\n",
    "                    .size().reset_index(name='purchase_counts')\n",
    "    result = result.join(purchase_times.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 3: whether or not purchase\n",
    "    #user_purd = set(val_raw[val_raw['event']=='8'].user_id_hash)\n",
    "    #result['past_buy'] = [1 if uid in user_purd else 0 for uid in result['user_id_hash']]\n",
    "    \n",
    "    # feature 4: total count of different events in event: top 50 events\n",
    "    event_list = ['0','5','1']\n",
    "    \n",
    "    for e in event_list:\n",
    "        event_tmp = val_raw[val_raw[\"event\"]==e].groupby(\"user_id_hash\").size().reset_index(name=f'event{e}_count')\n",
    "        result = result.join(event_tmp.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 5: median, last event time difference to cutoff time\n",
    "    first_last = val_raw.groupby(\"user_id_hash\")['event_timestamp'].agg(['median','last']).reset_index()\n",
    "    first_last['median_diff'] = cut_time - first_last['median']\n",
    "    first_last['last_diff'] = cut_time - first_last['last']\n",
    "    first_last['user_id_hash'] = first_last['user_id_hash'].astype(str)\n",
    "    result = result.join(first_last[['user_id_hash','median_diff','last_diff']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")\n",
    "\n",
    "    '''\n",
    "    session_avg = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('mean').reset_index(name='avg_duration')\n",
    "    session_avg['avg_duration'] = session_avg['avg_duration'].fillna(0)\n",
    "    result = result.join(session_avg[['user_id_hash','avg_duration']].set_index(\"user_id_hash\"),\\\n",
    "                 on=\"user_id_hash\", how=\"left\")  \n",
    "    '''\n",
    "    \n",
    "    session_sum = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('sum').reset_index(name='sum_duration')\n",
    "    session_sum['sum_duration'] = session_sum['sum_duration'].fillna(0)\n",
    "    result = result.join(session_sum[['user_id_hash','sum_duration']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    session_count = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('count').reset_index(name='session_count')\n",
    "    session_count['session_count'] = session_count['session_count'].fillna(0)\n",
    "    result = result.join(session_count[['user_id_hash','session_count']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    #result[['median_diff','last_diff','avg_duration','sum_duration']] = \\\n",
    "    result[['median_diff','last_diff','avg_duration','sum_duration']].apply(lambda x:x/3.6e+6)\n",
    "    # 8.64e+7 = 1 day in millseconds\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "#train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "train_feature_2 = features_event_2(train_raw,users_train,1542268800000,session_raw_train)\n",
    "\n",
    "#val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "#                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "val_feature_2 = features_event_2(val_raw,users_val,1543651199000, session_raw_val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature list for model1(7 days):\n",
    "- event_value\n",
    "- sum_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:12.163752Z",
     "start_time": "2019-02-25T03:22:08.673938Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_model_1(val_raw,val_user,cut_time,session_raw):# cut time is the cut stamp for feature/label \n",
    "    \n",
    "    eventvalue = val_raw[val_raw[\"event\"]==\"8\"][[\"user_id_hash\", \"event_value\"]].\\\n",
    "                groupby(\"user_id_hash\").sum().reset_index()\n",
    "    result = val_user.join(eventvalue.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "        \n",
    "    # feature 3: whether or not purchase\n",
    "    #user_purd = set(val_raw[val_raw['event']=='8'].user_id_hash)\n",
    "    #result['past_buy'] = [1 if uid in user_purd else 0 for uid in result['user_id_hash']]\n",
    "    \n",
    "    # feature 4: total count of different events in event: top 50 events\n",
    "\n",
    "    \n",
    "    session_sum = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('sum').reset_index(name='sum_duration')\n",
    "    session_sum['sum_duration'] = session_sum['sum_duration'].fillna(0)\n",
    "    result = result.join(session_sum[['user_id_hash','sum_duration']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "\n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "#train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "train_feature_m1 = features_model_1(train_raw,users_train,1542268800000,session_raw_train)\n",
    "\n",
    "#val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "#                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "val_feature_m1 = features_model_1(val_raw,users_val,1543651199000, session_raw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:44:54.398479Z",
     "start_time": "2019-02-25T01:44:54.388873Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>purchased1</th>\n",
       "      <th>purchased2</th>\n",
       "      <th>event_value</th>\n",
       "      <th>sum_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.492188</td>\n",
       "      <td>857156805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6074816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999524249720812f2d8c0390293efd58e1ac84d587a01c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc009148ee26d658e0240c7b7f6a258790a457737f96e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  purchased1  purchased2  \\\n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...           0           1   \n",
       "1  43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...           0           0   \n",
       "2  999524249720812f2d8c0390293efd58e1ac84d587a01c...           0           0   \n",
       "3  4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...           0           0   \n",
       "4  dc009148ee26d658e0240c7b7f6a258790a457737f96e8...           0           0   \n",
       "\n",
       "   event_value  sum_duration  \n",
       "0     3.492188   857156805.0  \n",
       "1     0.000000     6074816.0  \n",
       "2     0.000000           0.0  \n",
       "3     0.000000           0.0  \n",
       "4     0.000000           0.0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_m1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature list for model1(15 days):\n",
    "- median_diff\n",
    "- purchase_counts\n",
    "- last_diff\n",
    "- session_count\n",
    "- sum_duration\n",
    "- event 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:21:56.849977Z",
     "start_time": "2019-02-25T03:21:41.470372Z"
    }
   },
   "outputs": [],
   "source": [
    "def features_model_2(val_raw,val_user,cut_time,session_raw):# cut time is the cut stamp for feature/label \n",
    "    \n",
    "    # feature 2: number of purchase\n",
    "    purchase_times = val_raw[val_raw[\"event\"]==\"8\"].groupby(\"user_id_hash\")\\\n",
    "                    .size().reset_index(name='purchase_counts')\n",
    "    result = val_user.join(purchase_times.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    # feature 3: whether or not purchase\n",
    "    #user_purd = set(val_raw[val_raw['event']=='8'].user_id_hash)\n",
    "    #result['past_buy'] = [1 if uid in user_purd else 0 for uid in result['user_id_hash']]\n",
    "    \n",
    "    # feature 4: total count of different events in event: top 50 events\n",
    "\n",
    "    # feature 5: median, last event time difference to cutoff time\n",
    "    first_last = val_raw.groupby(\"user_id_hash\")['event_timestamp'].agg(['median','last']).reset_index()\n",
    "    first_last['median_diff'] = cut_time - first_last['median']\n",
    "    first_last['last_diff'] = cut_time - first_last['last']\n",
    "    first_last['user_id_hash'] = first_last['user_id_hash'].astype(str)\n",
    "    result = result.join(first_last[['user_id_hash','median_diff','last_diff']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    session_sum = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('sum').reset_index(name='sum_duration')\n",
    "    session_sum['sum_duration'] = session_sum['sum_duration'].fillna(0)\n",
    "    result = result.join(session_sum[['user_id_hash','sum_duration']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    session_count = session_raw_val.groupby(\"user_id_hash\")[\"previous_sessions_duration\"].\\\n",
    "    agg('count').reset_index(name='session_count')\n",
    "    session_count['session_count'] = session_count['session_count'].fillna(0)\n",
    "    result = result.join(session_count[['user_id_hash','session_count']].set_index(\"user_id_hash\"),\\\n",
    "                         on=\"user_id_hash\", how=\"left\")  \n",
    "    \n",
    "    event_list = ['5']\n",
    "    \n",
    "    for e in event_list:\n",
    "        event_tmp = val_raw[val_raw[\"event\"]==e].groupby(\"user_id_hash\").size().reset_index(name=f'event{e}_count')\n",
    "        result = result.join(event_tmp.set_index(\"user_id_hash\"), on=\"user_id_hash\", how=\"left\")\n",
    "    \n",
    "    \n",
    "    return result\n",
    "    \n",
    "\n",
    "#train_raw = event_df[(event_df[\"event_timestamp\"] < 1542268800000)] # Oct 1- Nov15\n",
    "train_feature_m2 = features_model_2(train_raw,users_train,1542268800000,session_raw_train)\n",
    "\n",
    "#val_raw = event_df[(event_df[\"event_timestamp\"] >= 1539586800000) &  # Oct15 - Nov30\n",
    "#                   (event_df[\"event_timestamp\"] < 1543651199000)]\n",
    "val_feature_m2 = features_model_2(val_raw,users_val,1543651199000, session_raw_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:21:56.872101Z",
     "start_time": "2019-02-25T03:21:56.855458Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>purchased1</th>\n",
       "      <th>purchased2</th>\n",
       "      <th>purchase_counts</th>\n",
       "      <th>median_diff</th>\n",
       "      <th>last_diff</th>\n",
       "      <th>sum_duration</th>\n",
       "      <th>session_count</th>\n",
       "      <th>event5_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9943447915df3a45fd6720a026af905b6da6b56a37701b...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.162291e+09</td>\n",
       "      <td>3.265969e+08</td>\n",
       "      <td>857156805.0</td>\n",
       "      <td>35</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.815455e+08</td>\n",
       "      <td>3.398837e+08</td>\n",
       "      <td>6074816.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>999524249720812f2d8c0390293efd58e1ac84d587a01c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.438209e+09</td>\n",
       "      <td>2.437954e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dc009148ee26d658e0240c7b7f6a258790a457737f96e8...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.045302e+09</td>\n",
       "      <td>1.902918e+09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  purchased1  purchased2  \\\n",
       "0  9943447915df3a45fd6720a026af905b6da6b56a37701b...           0           1   \n",
       "1  43f75f8042d3c80c45e222bdd09267f4584684c54d6fae...           0           0   \n",
       "2  999524249720812f2d8c0390293efd58e1ac84d587a01c...           0           0   \n",
       "3  4e6bc35cf7fd79a5312047651e7865915f4a6bec193cf2...           0           0   \n",
       "4  dc009148ee26d658e0240c7b7f6a258790a457737f96e8...           0           0   \n",
       "\n",
       "   purchase_counts   median_diff     last_diff  sum_duration  session_count  \\\n",
       "0                1  2.162291e+09  3.265969e+08   857156805.0             35   \n",
       "1                0  3.815455e+08  3.398837e+08     6074816.0              3   \n",
       "2                0  2.438209e+09  2.437954e+09           0.0              1   \n",
       "3                0           NaN           NaN           0.0              1   \n",
       "4                0  2.045302e+09  1.902918e+09           0.0              1   \n",
       "\n",
       "   event5_count  \n",
       "0            22  \n",
       "1             3  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_m2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X,y split for MODEL1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:12.382066Z",
     "start_time": "2019-02-25T03:22:12.358407Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_m1 = train_feature_m1[train_feature_m1.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "y_train_1 = train_feature_m1[[\"purchased1\"]]\n",
    "X_val_m1 = val_feature_m1[val_feature_m1.columns.difference([\"purchased1\",\"purchased2\",'user_id_hash'])]\n",
    "y_val_1 = val_feature_m1[['purchased1']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### X,y split for MODEL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:21:56.959847Z",
     "start_time": "2019-02-25T03:21:56.876365Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_m2 = train_feature_m2[train_feature_m2.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "y_train_2 = train_feature_m2[[\"purchased2\"]]\n",
    "X_val_m2 = val_feature_m2[val_feature_m2.columns.difference([\"purchased1\",\"purchased2\",'user_id_hash'])]\n",
    "y_val_2 = val_feature_m2[['purchased2']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search on Light GBM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:19:40.095219Z",
     "start_time": "2019-02-25T03:05:13.882967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random search start...\n",
      "* training model1_7day \n",
      "--> Best AUC:0.9743335859063035 using {'n_estimators': 350, 'bagging_fraction': 0.7, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 3, 'boosting_type': 'dart', 'max_depth': 4, 'feature_fraction': 0.9, 'lambda_l1': 0, 'objective': 'binary', 'metric': 'auc'}\n",
      "* training model2_14day \n",
      "--> Best AUC:0.9658687632067481 using {'n_estimators': 250, 'bagging_fraction': 0.7, 'learning_rate': 0.1, 'is_unbalance': True, 'max_bin': 18, 'boosting_type': 'gbdt', 'max_depth': 2, 'feature_fraction': 0.9, 'lambda_l1': 30, 'objective': 'binary', 'metric': 'auc'}\n"
     ]
    }
   ],
   "source": [
    "## Random Search\n",
    "# loop for random search\n",
    "n_iterations=20\n",
    "\n",
    "print (\"Random search start...\")\n",
    "\n",
    "for col in ['model1_7day','model2_14day']:\n",
    "    print(f\"* training {col} \")\n",
    "    #y = target[col]\n",
    "    roc_auc_mean = []\n",
    "    dict_list = []\n",
    "    \n",
    "    for i in range(0, n_iterations):\n",
    "\n",
    "        param_dist = {'n_estimators' : choice([250,300,350,400,450]),\n",
    "                  'bagging_fraction': choice([0.5, 0.7, 0.8, 0.9]),\n",
    "                  'learning_rate': choice([0.05, 0.1, 0.3, 0.5]),\n",
    "                  'is_unbalance': True,\n",
    "                  'max_bin': choice([3, 5, 10, 15, 18, 20, 25]),\n",
    "                  'boosting_type' : choice(['gbdt', 'dart']),\n",
    "                  'max_depth': choice([2,3,4,5]),      \n",
    "                  'feature_fraction': choice([0.7, 0.8, 0.9]),\n",
    "                  'lambda_l1': choice([0, 10, 20, 30, 40]),\n",
    "                  'objective': 'binary', \n",
    "                  'metric': 'auc'} \n",
    "\n",
    "        roc_l = []\n",
    "        \n",
    "       # y_train_1,y_train_2,X_train\n",
    "       # y_val_1,y_val_2,X_val\n",
    "\n",
    "        # training\n",
    "        if col == 'model1_7day':\n",
    "            X_train = X_train_m1\n",
    "            X_val = X_val_m1\n",
    "            y_train = y_train_1\n",
    "            y_val = y_val_1\n",
    "        else: \n",
    "            X_train = X_train_m2\n",
    "            X_val = X_val_m2\n",
    "            y_train = y_train_2\n",
    "            y_val = y_val_2\n",
    "            \n",
    "        gbm = lgb.LGBMClassifier(**param_dist)\n",
    "        gbm.fit(X_train,y_train)\n",
    "        # predicting\n",
    "        y_pred = np.round(gbm.predict_proba(X_val)[:,1],3)\n",
    "        \n",
    "        roc = roc_auc_score(y_val, y_pred)\n",
    "        roc_l.append(roc)\n",
    "\n",
    "        roc_array = np.asarray(roc_l)\n",
    "\n",
    "        roc_auc_mean.append(roc_array.mean())\n",
    "        dict_list.append(param_dist)\n",
    "        gc.collect()\n",
    "        \n",
    "\n",
    "    results_pd = pd.DataFrame({\"roc_auc_mean\": roc_auc_mean,\"parameters\": dict_list})    \n",
    "    results_pd.sort_values(\"roc_auc_mean\", ascending = False, axis = 0, inplace = True)\n",
    "    \n",
    "    top_pd = results_pd.head(1)\n",
    "    \n",
    "    print(f\"--> Best AUC:{top_pd.iloc[0,0]} using {top_pd.iloc[0,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 7 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:53.362510Z",
     "start_time": "2019-02-25T03:22:26.272988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score = 0.9743335859063035\n",
      "Time use:27.083s\n"
     ]
    }
   ],
   "source": [
    "# using the results from random search\n",
    "para_list_7days = {'n_estimators': 350, 'bagging_fraction': 0.7, 'learning_rate': 0.1, \\\n",
    "                   'is_unbalance': True, 'max_bin': 3, 'boosting_type': 'dart', 'max_depth': 4, \\\n",
    "                   'feature_fraction': 0.9, 'lambda_l1': 0, 'objective': 'binary', 'metric': 'auc'}\n",
    "t = time.time()\n",
    "# Model for 7 days\n",
    "param = para_list_7days\n",
    "gbm = lgb.LGBMClassifier(**param)\n",
    "gbm.fit(X_train_m1, y_train_1)\n",
    "# predicting\n",
    "probabilities = gbm.predict_proba(X_val_m1)\n",
    "#preds = gbm.predict(X_val_m1)\n",
    "score = probabilities[:, 1]\n",
    "\n",
    "print(f'auc score = {roc_auc_score(y_val_1,score)}')\n",
    "print(f\"Time use:{time.time()-t:.3f}s\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:53.387964Z",
     "start_time": "2019-02-25T03:22:53.371536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>event5_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350</td>\n",
       "      <td>last_diff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Value       Feature\n",
       "0    350  event5_count\n",
       "1    350     last_diff"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(sorted(zip(gbm.feature_importances_,X_train.columns)), columns=['Value','Feature'])\n",
    "#sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for 14 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:59.832891Z",
     "start_time": "2019-02-25T03:22:53.392394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc score = 0.966007955561583\n",
      "Time use:6.430s\n"
     ]
    }
   ],
   "source": [
    "# using the results from random search\n",
    "para_list_14days = {'n_estimators': 250, 'bagging_fraction': 0.7, 'learning_rate': 0.1, \\\n",
    "                    'is_unbalance': True, 'max_bin': 18, 'boosting_type': 'gbdt', 'max_depth': 2,\\\n",
    "                    'feature_fraction': 0.9, 'lambda_l1': 30, 'objective': 'binary', 'metric': 'auc'}\n",
    "\n",
    "t = time.time()\n",
    "# Model for 7 days\n",
    "param = para_list_14days\n",
    "gbm2 = lgb.LGBMClassifier(**param)\n",
    "gbm2.fit(X_train_m2, y_train_2)\n",
    "# predicting\n",
    "probabilities = gbm2.predict_proba(X_val_m2)\n",
    "#preds = gbm2.predict(X_val)\n",
    "score = probabilities[:, 1]\n",
    "print(f'auc score = {roc_auc_score(y_val_2,score)}')\n",
    "print(f\"Time use:{time.time()-t:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:22:59.859326Z",
     "start_time": "2019-02-25T03:22:59.844095Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Value</th>\n",
       "      <th>Feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>last_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83</td>\n",
       "      <td>session_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>93</td>\n",
       "      <td>median_diff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>103</td>\n",
       "      <td>purchase_counts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139</td>\n",
       "      <td>event5_count</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>172</td>\n",
       "      <td>sum_duration</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Value          Feature\n",
       "0     60        last_diff\n",
       "1     83    session_count\n",
       "2     93      median_diff\n",
       "3    103  purchase_counts\n",
       "4    139     event5_count\n",
       "5    172     sum_duration"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature importance for model 2\n",
    "pd.DataFrame(sorted(zip(gbm2.feature_importances_,X_train.columns)), columns=['Value','Feature'])\n",
    "#sort_values(by=['value'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict on the test set\n",
    "\n",
    "- test features: Nov1 - Dec15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:10.848141Z",
     "start_time": "2019-02-25T03:23:10.340747Z"
    }
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"/Users/nanlin/msds/Adv_ML/leanplum/data/LeanPlum/sample_submission_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:30.060389Z",
     "start_time": "2019-02-25T03:23:15.955685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event_value</th>\n",
       "      <th>sum_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.492188</td>\n",
       "      <td>857156805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6074816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event_value  sum_duration\n",
       "0     3.492188   857156805.0\n",
       "1     0.000000     6074816.0\n",
       "2     0.000000           0.0\n",
       "3     0.000000           0.0\n",
       "4     0.000000           0.0"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#users = pd.DataFrame(list(events.user_id_hash.unique()))\n",
    "#users.columns = [\"user_id_hash\"]\n",
    "session_raw_test = session_part[(session_part['start_timestamp'] >= 1541055600000)] # Nov 1\n",
    "test_raw = event_df[(event_df[\"event_timestamp\"] >= 1541055600000)] # November 1\n",
    "user_test = users\n",
    "test_feature_m1 = features_model_1(test_raw,user_test,1544860800000,session_raw_test) # Dec 15\n",
    "X_test_m1 = test_feature_m1[test_feature_m1.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "X_test_m1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:50.042370Z",
     "start_time": "2019-02-25T03:23:30.062595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>event5_count</th>\n",
       "      <th>last_diff</th>\n",
       "      <th>median_diff</th>\n",
       "      <th>purchase_counts</th>\n",
       "      <th>session_count</th>\n",
       "      <th>sum_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>2.918597e+09</td>\n",
       "      <td>2.670147e+09</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>857156805.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2.931884e+09</td>\n",
       "      <td>2.973545e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6074816.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.337255e+09</td>\n",
       "      <td>2.337667e+09</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   event5_count     last_diff   median_diff  purchase_counts  session_count  \\\n",
       "0            17  2.918597e+09  2.670147e+09                1             35   \n",
       "1             3  2.931884e+09  2.973545e+09                0              3   \n",
       "2             0           NaN           NaN                0              1   \n",
       "3             1  2.337255e+09  2.337667e+09                0              1   \n",
       "4             0           NaN           NaN                0              1   \n",
       "\n",
       "   sum_duration  \n",
       "0   857156805.0  \n",
       "1     6074816.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_m2 = features_model_2(test_raw,user_test,1544860800000,session_raw_test) # Dec 15\n",
    "X_test_m2 = test_feature_m2[test_feature_m2.columns.difference(['purchased1','purchased2','user_id_hash'])]\n",
    "X_test_m2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:56.373861Z",
     "start_time": "2019-02-25T03:23:53.209661Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_1 = gbm.predict_proba(X_test_m1)\n",
    "pred_2 = gbm2.predict_proba(X_test_m2)\n",
    "\n",
    "test_feature[\"user_purchase_binary_7_days\"] = pd.DataFrame(pred_1[:,-1])\n",
    "test_feature[\"user_purchase_binary_14_days\"] = pd.DataFrame(pred_2[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:23:59.538026Z",
     "start_time": "2019-02-25T03:23:58.937612Z"
    }
   },
   "outputs": [],
   "source": [
    "sub = sample[['user_id_hash']].merge(test_feature[['user_id_hash','user_purchase_binary_7_days',\\\n",
    "                                             'user_purchase_binary_14_days']],on='user_id_hash',\\\n",
    "                               how='left')\n",
    "# for users do not have previous data, mark as 0\n",
    "sub = sub.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:24:10.974421Z",
     "start_time": "2019-02-25T03:24:10.964996Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e469dfaed039ead9110165d9bc457acb11609ca34057dc...</td>\n",
       "      <td>0.158793</td>\n",
       "      <td>0.101043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...</td>\n",
       "      <td>0.050371</td>\n",
       "      <td>0.003373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...</td>\n",
       "      <td>0.158793</td>\n",
       "      <td>0.032277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...</td>\n",
       "      <td>0.704024</td>\n",
       "      <td>0.383790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...</td>\n",
       "      <td>0.050371</td>\n",
       "      <td>0.174208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  e469dfaed039ead9110165d9bc457acb11609ca34057dc...   \n",
       "1  afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...   \n",
       "2  fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...   \n",
       "3  00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...   \n",
       "4  0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                     0.158793                      0.101043  \n",
       "1                     0.050371                      0.003373  \n",
       "2                     0.158793                      0.032277  \n",
       "3                     0.704024                      0.383790  \n",
       "4                     0.050371                      0.174208  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T01:16:04.233592Z",
     "start_time": "2019-02-25T01:16:04.224780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id_hash</th>\n",
       "      <th>user_purchase_binary_7_days</th>\n",
       "      <th>user_purchase_binary_14_days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e469dfaed039ead9110165d9bc457acb11609ca34057dc...</td>\n",
       "      <td>0.188482</td>\n",
       "      <td>0.095764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...</td>\n",
       "      <td>0.005693</td>\n",
       "      <td>0.000845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...</td>\n",
       "      <td>0.008461</td>\n",
       "      <td>0.005554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...</td>\n",
       "      <td>0.438206</td>\n",
       "      <td>0.584298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...</td>\n",
       "      <td>0.189409</td>\n",
       "      <td>0.213411</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        user_id_hash  \\\n",
       "0  e469dfaed039ead9110165d9bc457acb11609ca34057dc...   \n",
       "1  afcc639a324b6c598ef83d360450afa011cb2dd1358bf9...   \n",
       "2  fd5a7cf211d08e3e00f7be6a9df6e6ea3d2e5c22a5d9c3...   \n",
       "3  00bfff98b9d0329f014c2eeac7ce47cd18b2bc6e10d608...   \n",
       "4  0d298f3638c43e915c119d4935e1ce8d168f81b5e3e8c1...   \n",
       "\n",
       "   user_purchase_binary_7_days  user_purchase_binary_14_days  \n",
       "0                     0.188482                      0.095764  \n",
       "1                     0.005693                      0.000845  \n",
       "2                     0.008461                      0.005554  \n",
       "3                     0.438206                      0.584298  \n",
       "4                     0.189409                      0.213411  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-25T03:24:24.857096Z",
     "start_time": "2019-02-25T03:24:23.329503Z"
    }
   },
   "outputs": [],
   "source": [
    "sub.to_csv(\"/Users/nanlin/msds/Adv_ML/leanplum/data/LeanPlum/submission_9\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
